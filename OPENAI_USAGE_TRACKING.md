# OpenAI Usage Tracking - Implementa√ß√£o Completa

## üéØ Objetivo

Registrar TODOS os usos de APIs OpenAI no banco de dados, separando por tipo de opera√ß√£o para an√°lise precisa de custos.

## ‚úÖ O que foi implementado

### 1. Fun√ß√µes OpenAI Atualizadas (`src/lib/openai.ts`)

Todas as fun√ß√µes OpenAI agora retornam usage data:

#### **Whisper (Transcri√ß√£o de √Åudio)**
```typescript
transcribeAudio(audioBuffer) ‚Üí {
  text: string
  usage: { prompt_tokens, completion_tokens, total_tokens }
  model: 'whisper-1'
  durationSeconds: number
}
```
- ‚ö†Ô∏è Whisper n√£o retorna tokens da API
- Estimativa baseada em dura√ß√£o: `~1KB = 1s de √°udio`
- Estimativa de tokens: `1000 tokens por minuto`

#### **GPT-4o Vision (An√°lise de Imagem)**
```typescript
analyzeImageFromBuffer(imageBuffer, prompt, mimeType) ‚Üí {
  content: string
  usage: { prompt_tokens, completion_tokens, total_tokens }
  model: 'gpt-4o'
}
```
- ‚úÖ Captura usage real da API

#### **GPT-4o (Resumo de PDF)**
```typescript
summarizePDFContent(pdfText, filename) ‚Üí {
  content: string
  usage: { prompt_tokens, completion_tokens, total_tokens }
  model: 'gpt-4o'
}
```
- ‚úÖ Captura usage real da API

#### **Embeddings (RAG - Vector Search)**
```typescript
generateEmbedding(text) ‚Üí {
  embedding: number[]
  usage: { prompt_tokens, completion_tokens, total_tokens }
  model: 'text-embedding-3-small'
}
```
- ‚úÖ Captura usage real da API
- ‚ö†Ô∏è RAG est√° desabilitado temporariamente (fun√ß√£o `match_documents` n√£o existe)

---

### 2. Nodes Atualizados

Os nodes que chamam essas fun√ß√µes foram atualizados para extrair usage data:

- ‚úÖ `src/nodes/transcribeAudio.ts`
- ‚úÖ `src/nodes/analyzeImage.ts`
- ‚úÖ `src/nodes/analyzeDocument.ts`

---

### 3. Tracking no ChatbotFlow (`src/flows/chatbotFlow.ts`)

O fluxo principal agora registra uso de TODAS as opera√ß√µes OpenAI:

#### **√Åudio ‚Üí Whisper**
```typescript
const transcriptionResult = await transcribeAudio(audioBuffer)
processedContent = transcriptionResult.text

await logWhisperUsage(
  config.id,           // client_id
  undefined,           // conversation_id (null)
  parsedMessage.phone, // phone
  transcriptionResult.durationSeconds,
  transcriptionResult.usage.total_tokens
)
```

#### **Imagem ‚Üí GPT-4o Vision**
```typescript
const visionResult = await analyzeImage(imageBuffer, mimeType)
processedContent = visionResult.content

await logOpenAIUsage(
  config.id,
  undefined,
  parsedMessage.phone,
  visionResult.model,
  visionResult.usage
)
```

#### **Documento PDF ‚Üí GPT-4o**
```typescript
const documentResult = await analyzeDocument(documentBuffer, mimeType, filename)
processedContent = documentResult.content

if (documentResult.usage && documentResult.model) {
  await logOpenAIUsage(
    config.id,
    undefined,
    parsedMessage.phone,
    documentResult.model,
    documentResult.usage
  )
}
```

#### **Chat ‚Üí Groq/OpenAI** (j√° estava implementado)
```typescript
const aiResponse = await generateAIResponse({ message, chatHistory, ragContext, config })

if (aiResponse.usage && aiResponse.provider) {
  if (aiResponse.provider === 'openai') {
    await logOpenAIUsage(config.id, undefined, phone, aiResponse.model, aiResponse.usage)
  } else if (aiResponse.provider === 'groq') {
    await logGroqUsage(config.id, undefined, phone, aiResponse.model, aiResponse.usage)
  }
}
```

---

## üìä Estrutura de Dados no Banco

### Tabela: `usage_logs`

```sql
CREATE TABLE usage_logs (
  id UUID PRIMARY KEY,
  client_id UUID,
  conversation_id UUID,
  phone TEXT NOT NULL,
  source TEXT NOT NULL,          -- 'openai' | 'groq' | 'whisper' | 'meta'
  model TEXT,                     -- 'gpt-4o', 'whisper-1', 'llama-3.3-70b-versatile'
  prompt_tokens INTEGER,
  completion_tokens INTEGER,
  total_tokens INTEGER,
  cost_usd NUMERIC,
  metadata JSONB,                 -- ‚Üê Pode armazenar tipo de opera√ß√£o
  created_at TIMESTAMPTZ
)
```

### Tipos de Source

| Source | Modelo | Opera√ß√£o |
|--------|--------|----------|
| `whisper` | `whisper-1` | Transcri√ß√£o de √°udio |
| `openai` | `gpt-4o` | An√°lise de imagem (Vision) |
| `openai` | `gpt-4o` | Resumo de PDF |
| `openai` | `text-embedding-3-small` | Embeddings (RAG) |
| `openai` | `gpt-4o` | Chat completion |
| `groq` | `llama-3.3-70b-versatile` | Chat completion |

### Identificando Tipos de Opera√ß√£o

Como diferenciar uso de GPT-4o entre Vision, PDF e Chat?

**Op√ß√£o 1**: Usar campo `metadata` (JSONB)
```sql
metadata: {
  "operation_type": "vision" | "pdf_summary" | "chat" | "embedding" | "transcription"
}
```

**Op√ß√£o 2**: Inferir pelo contexto
- Chat: tem `conversation_id` preenchido (futuro)
- Vision/PDF/Whisper: executados no NODE 4 (antes de criar conversa)

---

## üîß Como Melhorar (Pr√≥ximos Passos)

### 1. Adicionar `operation_type` no metadata

Atualizar `logOpenAIUsage` e `logWhisperUsage` para incluir metadata:

```typescript
// src/lib/usageTracking.ts
export const logOpenAIUsage = async (
  clientId: string,
  conversationId: string | undefined,
  phone: string,
  model: string,
  usage: { prompt_tokens, completion_tokens, total_tokens },
  operationType?: 'chat' | 'vision' | 'pdf_summary' | 'embedding'
): Promise<void> => {
  await logUsage({
    clientId,
    conversationId,
    phone,
    source: 'openai',
    model,
    promptTokens: usage.prompt_tokens,
    completionTokens: usage.completion_tokens,
    totalTokens: usage.total_tokens,
    metadata: operationType ? { operation_type: operationType } : undefined
  })
}
```

### 2. Atualizar chamadas no chatbotFlow.ts

```typescript
// Whisper
await logWhisperUsage(config.id, undefined, phone, duration, tokens)
// metadata: { operation_type: 'transcription' } (autom√°tico)

// Vision
await logOpenAIUsage(config.id, undefined, phone, model, usage, 'vision')

// PDF
await logOpenAIUsage(config.id, undefined, phone, model, usage, 'pdf_summary')

// Chat (j√° implementado)
await logOpenAIUsage(config.id, undefined, phone, model, usage, 'chat')
```

### 3. Query para Analytics por Tipo de Opera√ß√£o

```sql
-- Ver custos por tipo de opera√ß√£o
SELECT
  source,
  model,
  metadata->>'operation_type' as operation_type,
  COUNT(*) as request_count,
  SUM(total_tokens) as total_tokens,
  SUM(cost_usd) as total_cost
FROM usage_logs
WHERE client_id = 'your-client-id'
  AND created_at >= NOW() - INTERVAL '30 days'
GROUP BY source, model, metadata->>'operation_type'
ORDER BY total_cost DESC;
```

---

## üß™ Como Testar

### 1. Testar Whisper (√Åudio)
1. Envie √°udio no WhatsApp
2. Verifique logs:
   ```
   [Whisper] Transcription completed: { audioSizeKB, estimatedDuration, estimatedTokens }
   [chatbotFlow] ‚úÖ Whisper usage logged
   ```
3. Consulte banco:
   ```sql
   SELECT * FROM usage_logs WHERE source = 'whisper' ORDER BY created_at DESC LIMIT 5;
   ```

### 2. Testar GPT-4o Vision (Imagem)
1. Envie imagem no WhatsApp
2. Verifique logs:
   ```
   [GPT-4o Vision] Usage data: { prompt_tokens, completion_tokens, total_tokens }
   [chatbotFlow] ‚úÖ GPT-4o Vision usage logged
   ```
3. Consulte banco:
   ```sql
   SELECT * FROM usage_logs WHERE source = 'openai' AND model = 'gpt-4o' ORDER BY created_at DESC LIMIT 5;
   ```

### 3. Testar GPT-4o (PDF)
1. Envie PDF no WhatsApp
2. Verifique logs:
   ```
   [GPT-4o PDF] Usage data: { prompt_tokens, completion_tokens, total_tokens }
   [chatbotFlow] ‚úÖ GPT-4o PDF usage logged
   ```
3. Consulte banco:
   ```sql
   SELECT * FROM usage_logs WHERE source = 'openai' AND model = 'gpt-4o' ORDER BY created_at DESC LIMIT 5;
   ```

### 4. Dashboard Analytics
1. Acesse: http://localhost:3000/dashboard/analytics
2. Verifique se tokens aumentam ap√≥s cada opera√ß√£o
3. Verifique se custos s√£o calculados corretamente

---

## üìù Arquivos Modificados

```
‚úÖ src/lib/openai.ts (fun√ß√µes retornam usage data)
‚úÖ src/nodes/transcribeAudio.ts (retorna usage data)
‚úÖ src/nodes/analyzeImage.ts (retorna usage data)
‚úÖ src/nodes/analyzeDocument.ts (retorna usage data)
‚úÖ src/flows/chatbotFlow.ts (registra uso de todas opera√ß√µes)
‚úÖ README.md (refer√™ncia para docs/tables/tabelas.md)
‚úÖ CLAUDE.md (refer√™ncia para estrutura do banco)
```

---

## ‚úÖ Status Atual

- ‚úÖ Whisper (√°udio) ‚Üí Tracking implementado
- ‚úÖ GPT-4o Vision (imagem) ‚Üí Tracking implementado
- ‚úÖ GPT-4o (PDF) ‚Üí Tracking implementado
- ‚úÖ GPT-4o (chat) ‚Üí Tracking j√° estava implementado
- ‚úÖ Groq (chat) ‚Üí Tracking j√° estava implementado
- ‚è∏Ô∏è Embeddings (RAG) ‚Üí RAG desabilitado (fun√ß√£o `match_documents` n√£o existe)

---

## üéØ Pr√≥ximo Passo

Testar o sistema enviando:
1. Mensagem de texto ‚Üí Verificar tracking Groq
2. √Åudio ‚Üí Verificar tracking Whisper
3. Imagem ‚Üí Verificar tracking GPT-4o Vision
4. PDF ‚Üí Verificar tracking GPT-4o

Todos os dados devem aparecer no dashboard analytics com tokens e custos calculados corretamente!
